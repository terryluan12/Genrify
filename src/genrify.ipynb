{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "This Jupyter Notebook is meant to be executed directly from Google Colab in a plug and play manner.\n",
    "To enable this, the following code below can be run to set up the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "!git clone https://github.com/terryluan12/Genrify.git\n",
    "!cd Genrify && make\n",
    "\n",
    "sys.path.insert(0, \"Genrify/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run code below if using Google Drive for retrieving test data and CNN models for the Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Code\n",
    "The following code can be run to download the datasets and preprocess the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jack\\.conda\\envs\\aps360\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from datasources import download_datasets, convert_files_to_wav\n",
    "from preprocessing import preprocess\n",
    "from cnn.testhandler.TestHandler import TestHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to change subset_num to the subset which you are using\n",
    "subset_num = 0\n",
    "#Possible method values:\n",
    "#\"spec\", \"mel\", \"chroma\", \"mfcc\" to retrieve exclusive training datasets\n",
    "#\"create_testing_data\" to create testing data for the first time (not needed anymore due to option below)\n",
    "#\"test\" to unzip already preprocessed testing data from Google Drive\n",
    "method = None\n",
    "\n",
    "if method!=\"test\":\n",
    "    if method==\"create_testing_data\":\n",
    "        !unzip /content/drive/MyDrive/APS360_Team_Project/Test_Data/test_data_mp3.zip\n",
    "        data_dir = \"/content/test_data_mp3\"\n",
    "        output_dir = \"/content/Genrify/src/datasources/test_data_wav\"\n",
    "        convert_files_to_wav(data_dir, output_dir)\n",
    "    elif not os.path.isdir(\"Genrify/src/datasources/processed_data\"):\n",
    "        download_datasets(\"Genrify/src\")\n",
    "\n",
    "    preprocess(subset_num, method, \"Genrify/src\")\n",
    "    if method==\"create_testing_data\":\n",
    "      !zip -r '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_mel.zip' '/content/Genrify/src/datasources/mel'\n",
    "      !zip -r '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_spectrogram.zip' '/content/Genrify/src/datasources/spectrogram'\n",
    "      !zip -r '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_chroma.zip' '/content/Genrify/src/datasources/chroma'\n",
    "      !zip -r '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_mfcc.zip' '/content/Genrify/src/datasources/mfcc'\n",
    "else:\n",
    "    #Unzipping already preprocessed testing data\n",
    "    !unzip -q '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_mel.zip' -d '/'\n",
    "    !unzip -q '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_spectrogram.zip' -d '/'\n",
    "    !unzip -q '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_chroma.zip' -d '/'\n",
    "    !unzip -q '/content/drive/MyDrive/APS360 Team Project/Test_Data/test_mfcc.zip' -d '/'\n",
    "    test_handler = TestHandler(batch_size=1, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn import mfcc_model, training\n",
    "from utils import plot\n",
    "from cnn.datahandler.DataHandler import DataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "This code block implements ensemle learning for all of our best models\n",
    "\n",
    "Note that the batch size in used in TestHandler should be divide the total number of samples evenly. This is why batch_size=1 is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble import ensemble\n",
    "\n",
    "weak_learners=ensemble.get_weak_learners()\n",
    "print(\"Test Accuracy:\", ensemble.full_model([test_handler.spec_test_loader,test_handler.mfcc_test_loader,test_handler.chroma_test_loader,test_handler.mel_test_loader], weak_learners=[weak_learners[x] for x in [0,1,2,3]], cuda=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example to training an model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training example\n",
    "# mfcc_data_dir = os.path.join(\"Genrify\", \"src\", \"datasources\", \"mfcc\")\n",
    "# mfcc_data_handler = DataHandler(mfcc_data_dir, batch_size=32, num_workers=4)\n",
    "# lr = 1e-4\n",
    "# num_epochs = 30\n",
    "# mfcc_cnn = mfcc_model.MFCC_CNN()\n",
    "# print(f\"Learning rate: {1e-4}\")\n",
    "# training.train(mfcc_cnn, mfcc_data_handler.train_loader, mfcc_data_handler.val_loader, num_epochs, lr, 32)\n",
    "# model_path = training.get_model_name(mfcc_cnn.name, 32, lr, num_epochs-1)\n",
    "\n",
    "# # plot in the notebook\n",
    "# %matplotlib inline\n",
    "# plot.plot_training_curve(model_path)\n",
    "# plot.plot_confusion_matrix(model_path, range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training example for chroma\n",
    "#from cnn import chroma_model, training_chroma\n",
    "\n",
    "#chroma_data_dir = '/content/Genrify/src/datasources/chroma'\n",
    "#chroma_data_handler = DataHandler(chroma_data_dir, batch_size=32, num_workers=2)\n",
    "#lr = 1e-4\n",
    "#num_epochs = 60\n",
    "#chroma_cnn = chroma_model.ChromaClassifier()\n",
    "#print(f\"Learning rate: {lr}\")\n",
    "\n",
    "#training_chroma.train(chroma_cnn, chroma_data_handler.train_loader, chroma_data_handler.val_loader, num_epochs, lr, 32, 10, 0.1)\n",
    "#model_path = training.get_model_name(chroma_cnn.name, 32, lr, num_epochs-1)\n",
    "# %matplotlib inline\n",
    "# plot.plot_training_curve(model_path)\n",
    "# plot.plot_confusion_matrix(model_path, range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
